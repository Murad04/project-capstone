{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2024-11-18 Python-3.12.7 torch-2.2.2+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7055974 parameters, 0 gradients, 15.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 320x491 1 Brad Pitt, 1 Tom Cruise\n",
      "Speed: 154.0ms pre-process, 308.8ms inference, 22.0ms NMS per image at shape (1, 3, 448, 640)\n",
      "image 1/1: 320x491 1 Brad Pitt, 1 Tom Cruise\n",
      "Speed: 154.0ms pre-process, 308.8ms inference, 22.0ms NMS per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2, torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import pathlib\n",
    "\n",
    "# Patch PosixPath for Windows\n",
    "if pathlib.PosixPath != pathlib.WindowsPath:\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"\n",
    "    Load the YOLO model using ultralytics.\n",
    "    \"\"\"\n",
    "    model_path = r\"D:\\\\Personal\\\\codes\\\\project capstone\\\\cloud\\\\ml_yolov5\\\\best.pt\"\n",
    "    model = torch.hub.load('content\\\\yolov5', 'custom', path=model_path, source='local')\n",
    "    return model\n",
    "\n",
    "def detect_faces(model, image_path):\n",
    "    \"\"\"\n",
    "    Detect faces in the given image using the YOLO model.\n",
    "    \"\"\"\n",
    "    # Perform inference\n",
    "    results = model(image_path)\n",
    "    print(results)\n",
    "    return results\n",
    "\n",
    "def plot_detections(image_path, detections, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Plot bounding boxes on the image.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    for *box, confidence, cls in detections:\n",
    "        if confidence >= confidence_threshold:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
    "            # Put confidence label\n",
    "            label = f\"{confidence:.2f}\"\n",
    "            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the image\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    image_path = r\"C:\\\\Users\\\\DELL\\\\Downloads\\\\Screenshot 2024-11-30 134952.jpg\"\n",
    "    model = load_model()\n",
    "    detections = detect_faces(model, image_path)\n",
    "    print(detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
